{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiset\n",
    "\n",
    "class field(object):\n",
    "    def __init__(self, symbol, massDim, lorentz_rank, spinor_rank, spinor_rank_conj):\n",
    "        self.symbol = symbol #string symbol for field\n",
    "        self.lorentz_rank = lorentz_rank #int indicating lorentz rank of field\n",
    "        self.spinor_rank = spinor_rank #int indicating spinor rank of field\n",
    "        self.spinor_rank_conj = spinor_rank_conj #int indicating spinor rank of field\n",
    "        self.massDim= massDim #int indicating mass dimension of field\n",
    "    def info(self):\n",
    "        return 'symbol: ' + str(self.symbol) \\\n",
    "            + ' massDim: ' + str(self.massDim) \\\n",
    "            + ' lorentz_rank: ' + str(self.lorentz_rank) \\\n",
    "            + ' spinor_rank: ' + str(self.spinor_rank)\n",
    "    def get_symbol(self):\n",
    "        return self.symbol\n",
    "    def get_lorentz_rank(self):\n",
    "        return self.lorentz_rank\n",
    "    def get_spinor_rank(self):\n",
    "        return self.spinor_rank\n",
    "    def get_spinor_rank_conj(self):\n",
    "        return self.spinor_rank_conj\n",
    "    def get_massDim(self):\n",
    "        return self.massDim\n",
    "    def __eq__(self, other):\n",
    "        eq = (self.symbol == other.symbol)\n",
    "        return eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = field('D', 1, 1, 0, 0)\n",
    "F = field('F', 2, 2, 0, 0)\n",
    "S = field('Pb_S_P', 3, 0, 0, 0)\n",
    "V = field('Pb_V_P', 3, 0, 0, 0)\n",
    "T = field('Pb_T_P', 3, 0, 0, 0)\n",
    "Vp = field('Pb_Vp_P', 3, 0, 0, 0)\n",
    "Sp = field('Pb_Sp_P', 3, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['D', 'F', 'Pb_S_P', 'Pb_V_P', 'Pb_T_P', 'Pb_Vp_P', 'Pb_Sp_P'])\n",
      "dict_values([2, 1, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# field_combo indicates how many of each field are contained in the term in question\n",
    "field_dict = {'D': 2, 'F': 1, 'Pb_S_P': 0, 'Pb_V_P': 0, 'Pb_T_P': 0, 'Pb_Vp_P': 0, 'Pb_Sp_P': 0}\n",
    "print(field_dict.keys())\n",
    "print(field_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(field_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorentzRanks_list(field_dict):\n",
    "    symbol_list = list(field_dict.keys())\n",
    "    numFields_list = list(field_dict.values())\n",
    "    N_fieldTypes = len(symbol_list)\n",
    "    lorentzRanks = numFields_list\n",
    "    # if field is 'F', 'T', number of lorentz indices is twice the number of fields\n",
    "    for i in range(N_fieldTypes):\n",
    "        if symbol_list[i] == 'F' or symbol_list[i] == 'Pb_T_P':\n",
    "            lorentzRanks[i] *= 2\n",
    "    return lorentzRanks\n",
    "\n",
    "     \n",
    "def generate_lorentz_contractions(lorentzRanks_list):\n",
    "    # EXPLANATION: recursively generateS all ways of lorentz contracting fields. generate a set of sets of contractions. all sets of\n",
    "    # contractions should have the same number of contractions. take first index in lorentzRanks_list and contract it with every field with non-zero lorentz rank. \n",
    "    # for each such contraction, update the lorentzRanks_list by decrementing the lorentz rank of each contracted\n",
    "    # field by one for each contracted index. append this contraction to each of the sets of contractions output \n",
    "    # by generate_lorentz_contractions() acting on the decremented lorentzRanks_list. \n",
    "    \n",
    "    # base case: if the total number of free Lorentz indices is 0 or 1, return empty list of contraction sets \n",
    "    if sum(lorentzRanks_list) < 2:\n",
    "        contraction_list_list = [[]]\n",
    "        return contraction_list_list\n",
    "    \n",
    "    # set to store different sets of contractions\n",
    "    contraction_list_list = []\n",
    "    # variable to store number of distinct fields\n",
    "    N_fieldTypes = len(lorentzRanks_list)\n",
    "    \n",
    "    # find first field of non-zero rank for first index of contraction\n",
    "    for i in range(N_fieldTypes):\n",
    "        if lorentzRanks_list[i] >= 1:\n",
    "            i_start = i\n",
    "            #print('i_start: ' + str(i_start))\n",
    "            lorentzRanks_list[i_start] -= 1 #decrement lorentzRanks_list[i_start] by one\n",
    "            break\n",
    "            \n",
    "    # find all ways of contracting first non-zero lorentz rank field with other fields or itself \n",
    "    for i in range(i_start, N_fieldTypes):\n",
    "        #print(i)\n",
    "        if lorentzRanks_list[i] >= 1:\n",
    "            contraction = (i_start, i)\n",
    "            lorentzRanks_list_old = lorentzRanks_list.copy()\n",
    "            lorentzRanks_list_old[i] -= 1\n",
    "            #print('lorentzRanks_list_old: ' + str(lorentzRanks_list_old))\n",
    "            contraction_list_list_old = generate_lorentz_contractions(lorentzRanks_list_old)\n",
    "            #print('contraction_list_list_old: ' + str(contraction_list_list_old))\n",
    "            \n",
    "            for contraction_list_old in contraction_list_list_old:\n",
    "                #print(contraction_list_old)\n",
    "                contraction_list = contraction_list_old\n",
    "                contraction_list.append(contraction)\n",
    "                #print(contraction_list)\n",
    "                contraction_list_list.append(contraction_list) \n",
    "                #print(contraction_list_list)\n",
    "    return contraction_list_list\n",
    "        \n",
    "        \n",
    "def generate_lorentz_contractions_from_dict(field_dict):\n",
    "    lorentzRanks = lorentzRanks_list(field_dict)\n",
    "    contraction_list_list = generate_lorentz_contractions(lorentzRanks)\n",
    "    return contraction_list_list\n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_set_of_contraction_sets(field_dict):\n",
    "    contraction_list_list = generate_lorentz_contractions_from_dict(field_dict)\n",
    "    contraction_set_set = set()\n",
    "    for contraction_list in contraction_list_list:\n",
    "    #print('contraction_list:' +str(contraction_list))\n",
    "        contraction_set = FrozenMultiset(contraction_list)\n",
    "        contraction_set_set.add(contraction_set)\n",
    "    return contraction_set_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lorentzRanks = lorentzRanks_list(field_dict)\n",
    "lorentzRanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, 1), (0, 0)], [(0, 1), (0, 1)]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_lorentz_contractions(lorentzRanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(3, 3), (1, 1), (0, 0)],\n",
       " [(1, 3), (1, 3), (0, 0)],\n",
       " [(3, 3), (0, 1), (0, 1)],\n",
       " [(1, 3), (0, 3), (0, 1)],\n",
       " [(1, 3), (0, 1), (0, 3)],\n",
       " [(1, 1), (0, 3), (0, 3)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_dict2 = {'D': 2, 'F': 1, 'Pb_S_P': 0, 'Pb_V_P': 2, 'Pb_T_P': 0, 'Pb_Vp_P': 0, 'Pb_Sp_P': 0}\n",
    "\n",
    "generate_lorentz_contractions_from_dict(field_dict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUG: 4th and 5th contractions are redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraction_set:{(3, 3), (1, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 0)}\n",
      "contraction_set:{(3, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 3), (0, 3)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{FrozenMultiset({(1, 3): 2, (0, 0): 1}),\n",
       " FrozenMultiset({(1, 3): 1, (0, 3): 1, (0, 1): 1}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 1): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(3, 3): 1, (0, 1): 2}),\n",
       " FrozenMultiset({(1, 1): 1, (0, 3): 2})}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiset import FrozenMultiset\n",
    "contraction_list_list = generate_lorentz_contractions_from_dict(field_dict2)\n",
    "#print(contraction_list_list)\n",
    "contraction_set_set = set()\n",
    "for contraction_list in contraction_list_list:\n",
    "    #print('contraction_list:' +str(contraction_list))\n",
    "    contraction_set = FrozenMultiset(contraction_list)\n",
    "    print('contraction_set:' +str(contraction_set))\n",
    "    contraction_set_set.add(contraction_set)\n",
    "    \n",
    "contraction_set_set    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed redundant contraction set, but is there a way to avoid producing it in the first place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_dict4 = {'D': 4, 'F': 2, 'Pb_S_P': 0, 'Pb_V_P': 3, 'Pb_T_P': 0, 'Pb_Vp_P': 0, 'Pb_Sp_P': 0}\n",
    "\n",
    "len(generate_lorentz_contractions_from_dict(field_dict4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraction_set:{(3, 3), (1, 1), (1, 1), (0, 0), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 1), (0, 0), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 1), (0, 0), (0, 0)}\n",
      "contraction_set:{(1, 1), (1, 3), (1, 3), (0, 0), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 3), (0, 0), (0, 0)}\n",
      "contraction_set:{(3, 3), (1, 1), (0, 1), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 1), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 3), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 3), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 3), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 1), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 1), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 1), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 1), (1, 1), (0, 3), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 3), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 3), (0, 3), (0, 0)}\n",
      "contraction_set:{(3, 3), (1, 1), (0, 1), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 1), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 3), (0, 0), (0, 1)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 3), (0, 0), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 3), (0, 0), (0, 1)}\n",
      "contraction_set:{(3, 3), (1, 1), (0, 0), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 0), (0, 1), (0, 1)}\n",
      "contraction_set:{(3, 3), (0, 1), (0, 1), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 3), (0, 1), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 1), (0, 1), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 3), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 3), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 0), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 0), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 0), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 1), (0, 1), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 3), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 3), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 1), (0, 1), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 3), (0, 1), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 3), (0, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 1), (0, 0), (0, 3)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 1), (0, 0), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 1), (0, 0), (0, 3)}\n",
      "contraction_set:{(1, 1), (1, 1), (0, 3), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 3), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 3), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 0), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 0), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 0), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 3), (0, 1), (0, 1), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 3), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 3), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 1), (0, 1), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 3), (0, 1), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 3), (0, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 1), (1, 1), (0, 0), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 0), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 0), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 1), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 3), (0, 1), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 3), (0, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 1), (0, 1), (0, 3), (0, 3), (0, 3)}\n",
      "59\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "contraction_list_list4 = generate_lorentz_contractions_from_dict(field_dict4)\n",
    "contraction_set_set4 = set()\n",
    "for contraction_list in contraction_list_list4:\n",
    "    #print('contraction_list:' +str(contraction_list))\n",
    "    contraction_set = FrozenMultiset(contraction_list)\n",
    "    print('contraction_set:' +str(contraction_set))\n",
    "    contraction_set_set4.add(contraction_set)\n",
    "    \n",
    "#len(contraction_set_set4)\n",
    "print(len(contraction_list_list4))\n",
    "print(len(contraction_set_set4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, 1), (1, 1), (1, 1)]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_dict3 = {'D': 0, 'F': 3, 'Pb_S_P': 0, 'Pb_V_P': 0, 'Pb_T_P': 0, 'Pb_Vp_P': 0, 'Pb_Sp_P': 0}\n",
    "\n",
    "generate_lorentz_contractions_from_dict(field_dict3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUG: can't distinguish between contractions on the same F and contractions on different F's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(3, 3), (1, 3), (1, 1), (0, 1), (0, 0)],\n",
       " [(3, 3), (1, 1), (1, 3), (0, 1), (0, 0)],\n",
       " [(1, 3), (1, 3), (1, 3), (0, 1), (0, 0)],\n",
       " [(3, 3), (1, 1), (1, 1), (0, 3), (0, 0)],\n",
       " [(1, 3), (1, 3), (1, 1), (0, 3), (0, 0)],\n",
       " [(1, 3), (1, 1), (1, 3), (0, 3), (0, 0)],\n",
       " [(1, 1), (1, 3), (1, 3), (0, 3), (0, 0)],\n",
       " [(3, 3), (1, 3), (1, 1), (0, 0), (0, 1)],\n",
       " [(3, 3), (1, 1), (1, 3), (0, 0), (0, 1)],\n",
       " [(1, 3), (1, 3), (1, 3), (0, 0), (0, 1)],\n",
       " [(3, 3), (1, 3), (0, 1), (0, 1), (0, 1)],\n",
       " [(3, 3), (1, 1), (0, 3), (0, 1), (0, 1)],\n",
       " [(1, 3), (1, 3), (0, 3), (0, 1), (0, 1)],\n",
       " [(3, 3), (1, 1), (0, 1), (0, 3), (0, 1)],\n",
       " [(1, 3), (1, 3), (0, 1), (0, 3), (0, 1)],\n",
       " [(1, 3), (1, 1), (0, 3), (0, 3), (0, 1)],\n",
       " [(1, 1), (1, 3), (0, 3), (0, 3), (0, 1)],\n",
       " [(3, 3), (1, 1), (1, 1), (0, 0), (0, 3)],\n",
       " [(1, 3), (1, 3), (1, 1), (0, 0), (0, 3)],\n",
       " [(1, 3), (1, 1), (1, 3), (0, 0), (0, 3)],\n",
       " [(1, 1), (1, 3), (1, 3), (0, 0), (0, 3)],\n",
       " [(3, 3), (1, 1), (0, 1), (0, 1), (0, 3)],\n",
       " [(1, 3), (1, 3), (0, 1), (0, 1), (0, 3)],\n",
       " [(1, 3), (1, 1), (0, 3), (0, 1), (0, 3)],\n",
       " [(1, 1), (1, 3), (0, 3), (0, 1), (0, 3)],\n",
       " [(1, 3), (1, 1), (0, 1), (0, 3), (0, 3)],\n",
       " [(1, 1), (1, 3), (0, 1), (0, 3), (0, 3)],\n",
       " [(1, 1), (1, 1), (0, 3), (0, 3), (0, 3)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_dict5 = {'D': 3, 'F': 2, 'Pb_S_P': 0, 'Pb_V_P': 3, 'Pb_T_P': 0, 'Pb_Vp_P': 0, 'Pb_Sp_P': 0}\n",
    "\n",
    "generate_lorentz_contractions_from_dict(field_dict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraction_set:{(3, 3), (1, 3), (1, 1), (0, 1), (0, 0)}\n",
      "contraction_set:{(3, 3), (1, 1), (1, 3), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 3), (0, 1), (0, 0)}\n",
      "contraction_set:{(3, 3), (1, 1), (1, 1), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 1), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 1), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 1), (1, 3), (1, 3), (0, 3), (0, 0)}\n",
      "contraction_set:{(3, 3), (1, 3), (1, 1), (0, 0), (0, 1)}\n",
      "contraction_set:{(3, 3), (1, 1), (1, 3), (0, 0), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 3), (0, 0), (0, 1)}\n",
      "contraction_set:{(3, 3), (1, 3), (0, 1), (0, 1), (0, 1)}\n",
      "contraction_set:{(3, 3), (1, 1), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(3, 3), (1, 1), (0, 1), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 1), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(3, 3), (1, 1), (1, 1), (0, 0), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 1), (0, 0), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 1), (0, 0), (0, 3)}\n",
      "contraction_set:{(1, 1), (1, 3), (1, 3), (0, 0), (0, 3)}\n",
      "contraction_set:{(3, 3), (1, 1), (0, 1), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 1), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 1), (1, 1), (0, 3), (0, 3), (0, 3)}\n",
      "28\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{FrozenMultiset({(1, 1): 2, (0, 3): 3}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 1): 2, (0, 3): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(1, 3): 2, (1, 1): 1, (0, 3): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 3): 1, (1, 1): 1, (0, 1): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(1, 3): 2, (0, 3): 1, (0, 1): 2}),\n",
       " FrozenMultiset({(1, 3): 3, (0, 1): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 1): 1, (0, 3): 1, (0, 1): 2}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 3): 1, (0, 1): 3}),\n",
       " FrozenMultiset({(1, 3): 1, (1, 1): 1, (0, 3): 2, (0, 1): 1})}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contraction_list_list5 = generate_lorentz_contractions_from_dict(field_dict5)\n",
    "contraction_set_set5 = set()\n",
    "for contraction_list in contraction_list_list5:\n",
    "    #print('contraction_list:' +str(contraction_list))\n",
    "    contraction_set = FrozenMultiset(contraction_list)\n",
    "    print('contraction_set:' +str(contraction_set))\n",
    "    contraction_set_set5.add(contraction_set)\n",
    "    \n",
    "#len(contraction_set_set4)\n",
    "print(len(contraction_list_list5))\n",
    "print(len(contraction_set_set5))\n",
    "contraction_set_set5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{FrozenMultiset({(1, 1): 2, (0, 3): 3}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 1): 2, (0, 3): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(1, 3): 2, (1, 1): 1, (0, 3): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 3): 1, (1, 1): 1, (0, 1): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(1, 3): 2, (0, 3): 1, (0, 1): 2}),\n",
       " FrozenMultiset({(1, 3): 3, (0, 1): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 1): 1, (0, 3): 1, (0, 1): 2}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 3): 1, (0, 1): 3}),\n",
       " FrozenMultiset({(1, 3): 1, (1, 1): 1, (0, 3): 2, (0, 1): 1})}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test reduce_set_of_contraction_sets()\n",
    "reduce_set_of_contraction_sets(field_dict5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate all Field Combinations up to a Given Mass Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom multiset import Multiset\\n\\ndef generate_field_combos(massDim):\\n    # EXPLANATION: generate terms recursively. iterate through fields list, if mass dimension of field is less than\\n    # massDim, append it to combo, \\n    \\n    # base case\\n    if massDim < 1: \\n        return [[]]\\n    \\n    # declare field types\\n    D = field('D', 1, 1, 0, 0)\\n    F = field('F', 2, 2, 0, 0)\\n    S = field('Pb_S_P', 3, 0, 0, 0)\\n    V = field('Pb_V_P', 3, 0, 0, 0)\\n    T = field('Pb_T_P', 3, 0, 0, 0)\\n    Vp = field('Pb_Vp_P', 3, 0, 0, 0)\\n    Sp = field('Pb_Sp_P', 3, 0, 0, 0)\\n    \\n    # make list of field types\\n    fields = [D, F, S, V, T, Vp, Sp] \\n    \\n    # empty list to store different field combos\\n    list_of_field_combos = []\\n    \\n    for i in range(len(fields)):\\n        field_current = fields[i]\\n        massDim_current = field_current.get_massDim() \\n        massDimRes = massDim - massDim_current\\n        if massDimRes >= 0:\\n            print(massDimRes)\\n            list_of_field_combos_old = generate_field_combos(massDimRes)\\n            for field_combo_old in list_of_field_combos_old:\\n                field_combo = field_combo_old\\n                field_combo.append(field_current.get_symbol())\\n                list_of_field_combos.append(field_combo)\\n\\n    return list_of_field_combos\\n\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def generate_field_combos(massDim):\n",
    "    # EXPLANATION: generate terms recursively. iterate through fields list, if mass dimension of field is less than\n",
    "    # massDim, append it to combo, \n",
    "    \n",
    "    # base case\n",
    "    if massDim < 1: \n",
    "        return [[]]\n",
    "    \n",
    "    # declare field types\n",
    "    D = field('D', 1, 1, 0, 0)\n",
    "    F = field('F', 2, 2, 0, 0)\n",
    "    S = field('Pb_S_P', 3, 0, 0, 0)\n",
    "    V = field('Pb_V_P', 3, 0, 0, 0)\n",
    "    T = field('Pb_T_P', 3, 0, 0, 0)\n",
    "    Vp = field('Pb_Vp_P', 3, 0, 0, 0)\n",
    "    Sp = field('Pb_Sp_P', 3, 0, 0, 0)\n",
    "    \n",
    "    # make list of field types\n",
    "    fields = [D, F, S, V, T, Vp, Sp] \n",
    "    \n",
    "    # empty list to store different field combos\n",
    "    list_of_field_combos = []\n",
    "    \n",
    "    for i in range(len(fields)):\n",
    "        field_current = fields[i]\n",
    "        massDim_current = field_current.get_massDim() \n",
    "        massDimRes = massDim - massDim_current\n",
    "        if massDimRes >= 0:\n",
    "            print(massDimRes)\n",
    "            list_of_field_combos_old = generate_field_combos(massDimRes)\n",
    "            for field_combo_old in list_of_field_combos_old:\n",
    "                field_combo = field_combo_old\n",
    "                field_combo.append(field_current.get_symbol())\n",
    "                list_of_field_combos.append(field_combo)\n",
    "\n",
    "    return list_of_field_combos\n",
    "'''\n",
    "'''\n",
    "from multiset import Multiset\n",
    "\n",
    "def generate_field_combos(massDim):\n",
    "    # EXPLANATION: generate terms recursively. iterate through fields list, if mass dimension of field is less than\n",
    "    # massDim, append it to combo, \n",
    "    \n",
    "    # base case\n",
    "    if massDim < 1: \n",
    "        return [[]]\n",
    "    \n",
    "    # declare field types\n",
    "    D = field('D', 1, 1, 0, 0)\n",
    "    F = field('F', 2, 2, 0, 0)\n",
    "    S = field('Pb_S_P', 3, 0, 0, 0)\n",
    "    V = field('Pb_V_P', 3, 0, 0, 0)\n",
    "    T = field('Pb_T_P', 3, 0, 0, 0)\n",
    "    Vp = field('Pb_Vp_P', 3, 0, 0, 0)\n",
    "    Sp = field('Pb_Sp_P', 3, 0, 0, 0)\n",
    "    \n",
    "    # make list of field types\n",
    "    fields = [D, F, S, V, T, Vp, Sp] \n",
    "    \n",
    "    # empty list to store different field combos\n",
    "    list_of_field_combos = []\n",
    "    \n",
    "    for i in range(len(fields)):\n",
    "        field_current = fields[i]\n",
    "        massDim_current = field_current.get_massDim() \n",
    "        massDimRes = massDim - massDim_current\n",
    "        if massDimRes >= 0:\n",
    "            print(massDimRes)\n",
    "            list_of_field_combos_old = generate_field_combos(massDimRes)\n",
    "            for field_combo_old in list_of_field_combos_old:\n",
    "                field_combo = field_combo_old\n",
    "                field_combo.append(field_current.get_symbol())\n",
    "                list_of_field_combos.append(field_combo)\n",
    "\n",
    "    return list_of_field_combos\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbols_to_fields(field_combo_symbols):\n",
    "    field_combo = []\n",
    "    for field_symbol in field_combo_symbols:\n",
    "        if field_symbol == 'D':\n",
    "            field_combo.append(D)\n",
    "            continue\n",
    "        if field_symbol == 'F':\n",
    "            field_combo.append(F)\n",
    "            continue\n",
    "        if field_symbol == 'Pb_S_P':\n",
    "            field_combo.append(S)\n",
    "            continue\n",
    "        if field_symbol == 'Pb_V_P':\n",
    "            field_combo.append(V)\n",
    "            continue\n",
    "        if field_symbol == 'Pb_T_P':\n",
    "            field_combo.append(T)\n",
    "            continue\n",
    "        if field_symbol == 'Pb_Vp_P':\n",
    "            field_combo.append(Vp)\n",
    "            continue\n",
    "        if field_symbol == 'Pb_Sp_P':\n",
    "            field_combo.append(Sp)\n",
    "            continue\n",
    "         \n",
    "    return field_combo\n",
    "\n",
    "def totalMassDim(field_combo_symbols):\n",
    "    field_combo = symbols_to_fields(field_combo_symbols)\n",
    "    m = 0\n",
    "    for field in field_combo:\n",
    "        m += field.get_massDim()\n",
    "    return m\n",
    "\n",
    "def generate_field_combos(massDim):\n",
    "    # EXPLANATION: Generate all multisets of the symbols [D, F, S, V, T, Vp, Sp] up to massDim. store in a set of \n",
    "    # multisets called set_of_field_multisets. generate new multisets by adding each field to multisets in a set\n",
    "    # of multisets called front. remove a multiset from front after attempting to add each field to it. add an\n",
    "    # element to front only if after a field has been added, its mass dimension is still less than massDim. \n",
    "    \n",
    "    # declare field types\n",
    "    D = field('D', 1, 1, 0, 0)\n",
    "    F = field('F', 2, 2, 0, 0)\n",
    "    S = field('Pb_S_P', 3, 0, 0, 0)\n",
    "    V = field('Pb_V_P', 3, 0, 0, 0)\n",
    "    T = field('Pb_T_P', 3, 0, 0, 0)\n",
    "    Vp = field('Pb_Vp_P', 3, 0, 0, 0)\n",
    "    Sp = field('Pb_Sp_P', 3, 0, 0, 0)\n",
    "    \n",
    "    # make list of field types\n",
    "    fields = [D, F, S, V, T, Vp, Sp] \n",
    "    \n",
    "    # set of multisets\n",
    "    set_of_field_multisets = set() #set of multisets of field strings\n",
    "    front = set() #set of multisets of field strings, set of multisets to add to to make new multisets\n",
    "    \n",
    "    # initialize front\n",
    "    for item in fields: \n",
    "        if item.get_massDim() <= massDim:\n",
    "            front.add(FrozenMultiset([item.get_symbol()]))\n",
    "            set_of_field_multisets.add(FrozenMultiset([item.get_symbol()]))\n",
    "\n",
    "    # build set_of_multisets\n",
    "    while front:\n",
    "        #print('')\n",
    "        #print('front: ' + str(front))\n",
    "        front_new = front.copy()\n",
    "        for field_multiset in front:\n",
    "            #print('field_multiset: ' + str(field_multiset))\n",
    "            for item in fields:\n",
    "                #print('field item: ' + str(item.get_symbol()))\n",
    "                field_multiset_new = field_multiset.combine(FrozenMultiset([item.get_symbol()]))\n",
    "                #print('field_multiset_new: ' + str(field_multiset_new))\n",
    "                if totalMassDim(field_multiset_new) < massDim:\n",
    "                    set_of_field_multisets.add(field_multiset_new)\n",
    "                    front_new.add(field_multiset_new)\n",
    "                    #print('ADD TO FRONT: ' + str(field_multiset_new))\n",
    "                if totalMassDim(field_multiset_new) == massDim:\n",
    "                    set_of_field_multisets.add(field_multiset_new)\n",
    "            front_new.remove(field_multiset)\n",
    "        front = front_new\n",
    "        #print('front_new: ' + str(front_new))\n",
    "        #print('')\n",
    "    \n",
    "    return set_of_field_multisets\n",
    "                    \n",
    "                    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{D, D, Pb_S_P}\n",
      "{D, F, F}\n",
      "{Pb_Vp_P, D}\n",
      "{D, D, D, D, D}\n",
      "{D, D, Pb_V_P}\n",
      "{D, D}\n",
      "{D, D, D}\n",
      "{F, Pb_V_P}\n",
      "{D, Pb_V_P}\n",
      "{D, D, D, D}\n",
      "{Pb_V_P}\n",
      "{D}\n",
      "{Pb_Vp_P, D, D}\n",
      "{F, Pb_S_P}\n",
      "{Pb_Vp_P, F}\n",
      "{D, Pb_S_P}\n",
      "{Pb_T_P, F}\n",
      "{Pb_Sp_P}\n",
      "{Pb_Vp_P}\n",
      "{Pb_T_P, D}\n",
      "{D, Pb_Sp_P}\n",
      "{Pb_T_P}\n",
      "{D, F}\n",
      "{F, F}\n",
      "{F, Pb_Sp_P}\n",
      "{D, D, F}\n",
      "{F}\n",
      "{D, D, Pb_Sp_P}\n",
      "{Pb_T_P, D, D}\n",
      "{D, D, D, F}\n",
      "{Pb_S_P}\n"
     ]
    }
   ],
   "source": [
    "massDim = 5\n",
    "for item in generate_field_combos(massDim):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tested for massdim up to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
