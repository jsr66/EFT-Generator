{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiset\n",
    "\n",
    "class field(object):\n",
    "    def __init__(self, symbol, massDim, lorentz_rank, spinor_rank, spinor_rank_conj):\n",
    "        self.symbol = symbol #string symbol for field\n",
    "        self.lorentz_rank = lorentz_rank #int indicating lorentz rank of field\n",
    "        self.spinor_rank = spinor_rank #int indicating spinor rank of field\n",
    "        self.spinor_rank_conj = spinor_rank_conj #int indicating spinor rank of field\n",
    "        self.massDim= massDim #int indicating mass dimension of field\n",
    "    def info(self):\n",
    "        return 'symbol: ' + str(self.symbol) \\\n",
    "            + ' massDim: ' + str(self.massDim) \\\n",
    "            + ' lorentz_rank: ' + str(self.lorentz_rank) \\\n",
    "            + ' spinor_rank: ' + str(self.spinor_rank)\n",
    "    def get_symbol(self):\n",
    "        return self.symbol\n",
    "    def get_lorentz_rank(self):\n",
    "        return self.lorentz_rank\n",
    "    def get_spinor_rank(self):\n",
    "        return self.spinor_rank\n",
    "    def get_spinor_rank_conj(self):\n",
    "        return self.spinor_rank_conj\n",
    "    def get_massDim(self):\n",
    "        return self.massDim\n",
    "    def __eq__(self, other):\n",
    "        eq = (self.symbol == other.symbol)\n",
    "        return eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = field('D', 1, 1, 0, 0)\n",
    "F = field('F', 2, 2, 0, 0)\n",
    "S = field('Pb_S_P', 3, 0, 0, 0)\n",
    "V = field('Pb_V_P', 3, 1, 0, 0)\n",
    "T = field('Pb_T_P', 3, 2, 0, 0)\n",
    "Vp = field('Pb_Vp_P', 3, 1, 0, 0)\n",
    "Sp = field('Pb_Sp_P', 3, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['D', 'F', 'Pb_S_P', 'Pb_V_P', 'Pb_T_P', 'Pb_Vp_P', 'Pb_Sp_P'])\n",
      "dict_values([2, 1, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# field_combo indicates how many of each field are contained in the term in question\n",
    "field_dict = {'D': 2, 'F': 1, 'Pb_S_P': 0, 'Pb_V_P': 0, 'Pb_T_P': 0, 'Pb_Vp_P': 0, 'Pb_Sp_P': 0}\n",
    "print(field_dict.keys())\n",
    "print(field_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(field_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_symbolList_to_fieldList(symbol_list):\n",
    "    D = field('D', 1, 1, 0, 0)\n",
    "    F = field('F', 2, 2, 0, 0)\n",
    "    S = field('Pb_S_P', 3, 0, 0, 0)\n",
    "    V = field('Pb_V_P', 3, 1, 0, 0)\n",
    "    T = field('Pb_T_P', 3, 2, 0, 0)\n",
    "    Vp = field('Pb_Vp_P', 3, 1, 0, 0)\n",
    "    Sp = field('Pb_Sp_P', 3, 0, 0, 0)\n",
    "    \n",
    "    field_list = []\n",
    "    for i in range(len(symbol_list)):\n",
    "        if symbol_list[i] == 'D':\n",
    "            field_list.append(D)\n",
    "        if symbol_list[i] == 'F':\n",
    "            field_list.append(F)\n",
    "        if symbol_list[i] == 'Pb_S_P':\n",
    "            field_list.append(S)\n",
    "        if symbol_list[i] == 'Pb_V_P':\n",
    "            field_list.append(V)\n",
    "        if symbol_list[i] == 'Pb_T_P':\n",
    "            field_list.append(T)\n",
    "        if symbol_list[i] == 'Pb_Vp_P':\n",
    "            field_list.append(Vp)\n",
    "        if symbol_list[i] == 'Pb_Sp_P':\n",
    "            field_list.append(Sp)\n",
    "        \n",
    "    return field_list\n",
    "\n",
    "\n",
    "def lorentzRanks_list(field_dict):\n",
    "    symbol_list = list(field_dict.keys())\n",
    "    field_types = convert_symbolList_to_fieldList(symbol_list)\n",
    "    numFields_list = list(field_dict.values())\n",
    "    lor_ranks_list = [field_type.get_lorentz_rank() for field_type in field_types]\n",
    "    N_fieldTypes = len(symbol_list)\n",
    "    lorentzRanks = [num_fields*lor_rank for num_fields,lor_rank  in zip(numFields_list,lor_ranks_list)]\n",
    "    # if field is 'F', 'T', number of lorentz indices is twice the number of fields\n",
    "    #for i in range(N_fieldTypes):\n",
    "    #    if symbol_list[i] == 'F' or symbol_list[i] == 'Pb_T_P':\n",
    "    #        lorentzRanks[i] *= 2\n",
    "    return lorentzRanks\n",
    "\n",
    "     \n",
    "def generate_lorentz_contractions(lorentzRanks_list):\n",
    "    # EXPLANATION: recursively generateS all ways of lorentz contracting fields. generate a set of sets of contractions. all sets of\n",
    "    # contractions should have the same number of contractions. take first index in lorentzRanks_list and contract it with every field with non-zero lorentz rank. \n",
    "    # for each such contraction, update the lorentzRanks_list by decrementing the lorentz rank of each contracted\n",
    "    # field by one for each contracted index. append this contraction to each of the sets of contractions output \n",
    "    # by generate_lorentz_contractions() acting on the decremented lorentzRanks_list. \n",
    "    \n",
    "    # base case: if the total number of free Lorentz indices is 0 or 1, return empty list of contraction sets \n",
    "    if sum(lorentzRanks_list) < 2:\n",
    "        contraction_list_list = [[]]\n",
    "        return contraction_list_list\n",
    "    \n",
    "    # set to store different sets of contractions\n",
    "    contraction_list_list = []\n",
    "    # variable to store number of distinct fields\n",
    "    N_fieldTypes = len(lorentzRanks_list)\n",
    "    \n",
    "    # find first field of non-zero rank for first index of contraction\n",
    "    for i in range(N_fieldTypes):\n",
    "        if lorentzRanks_list[i] >= 1:\n",
    "            i_start = i\n",
    "            #print('i_start: ' + str(i_start))\n",
    "            lorentzRanks_list[i_start] -= 1 #decrement lorentzRanks_list[i_start] by one\n",
    "            break\n",
    "            \n",
    "    # find all ways of contracting first non-zero lorentz rank field with other fields or itself \n",
    "    for i in range(i_start, N_fieldTypes):\n",
    "        #print(i)\n",
    "        if lorentzRanks_list[i] >= 1:\n",
    "            contraction = (i_start, i)\n",
    "            lorentzRanks_list_old = lorentzRanks_list.copy()\n",
    "            lorentzRanks_list_old[i] -= 1\n",
    "            #print('lorentzRanks_list_old: ' + str(lorentzRanks_list_old))\n",
    "            contraction_list_list_old = generate_lorentz_contractions(lorentzRanks_list_old)\n",
    "            #print('contraction_list_list_old: ' + str(contraction_list_list_old))\n",
    "            \n",
    "            for contraction_list_old in contraction_list_list_old:\n",
    "                #print(contraction_list_old)\n",
    "                contraction_list = contraction_list_old\n",
    "                contraction_list.append(contraction)\n",
    "                #print(contraction_list)\n",
    "                contraction_list_list.append(contraction_list) \n",
    "                #print(contraction_list_list)\n",
    "    return contraction_list_list\n",
    "        \n",
    "        \n",
    "def generate_lorentz_contractions_from_dict(field_dict):\n",
    "    lorentzRanks = lorentzRanks_list(field_dict)\n",
    "    contraction_list_list = generate_lorentz_contractions(lorentzRanks)\n",
    "    return contraction_list_list\n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_set_of_contraction_sets(field_dict):\n",
    "    contraction_list_list = generate_lorentz_contractions_from_dict(field_dict)\n",
    "    contraction_set_set = set()\n",
    "    for contraction_list in contraction_list_list:\n",
    "    #print('contraction_list:' +str(contraction_list))\n",
    "        contraction_set = FrozenMultiset(contraction_list)\n",
    "        contraction_set_set.add(contraction_set)\n",
    "    return contraction_set_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.field at 0x118c67e10>,\n",
       " <__main__.field at 0x118c676d8>,\n",
       " <__main__.field at 0x118c67f28>,\n",
       " <__main__.field at 0x118c67518>,\n",
       " <__main__.field at 0x112336550>,\n",
       " <__main__.field at 0x1179ba8d0>,\n",
       " <__main__.field at 0x1179baa58>]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_symbolList_to_fieldList(list(field_dict.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 0, 2, 0, 0, 0]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_dict1 = {'D': 2, 'F': 1, 'Pb_S_P': 1, 'Pb_V_P': 2, 'Pb_T_P': 0, 'Pb_Vp_P': 0, 'Pb_Sp_P': 1}\n",
    "lorentzRanks = lorentzRanks_list(field_dict1)\n",
    "lorentzRanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(3, 3), (1, 1), (0, 0)],\n",
       " [(1, 3), (1, 3), (0, 0)],\n",
       " [(3, 3), (0, 1), (0, 1)],\n",
       " [(1, 3), (0, 3), (0, 1)],\n",
       " [(1, 3), (0, 1), (0, 3)],\n",
       " [(1, 1), (0, 3), (0, 3)]]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_lorentz_contractions(lorentzRanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(3, 3), (1, 1), (0, 0)],\n",
       " [(1, 3), (1, 3), (0, 0)],\n",
       " [(3, 3), (0, 1), (0, 1)],\n",
       " [(1, 3), (0, 3), (0, 1)],\n",
       " [(1, 3), (0, 1), (0, 3)],\n",
       " [(1, 1), (0, 3), (0, 3)]]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_dict2 = {'D': 2, 'F': 1, 'Pb_S_P': 0, 'Pb_V_P': 2, 'Pb_T_P': 0, 'Pb_Vp_P': 0, 'Pb_Sp_P': 0}\n",
    "\n",
    "generate_lorentz_contractions_from_dict(field_dict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUG: 4th and 5th contractions are redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraction_set:{(3, 3), (1, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 0)}\n",
      "contraction_set:{(3, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 3), (0, 3)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{FrozenMultiset({(1, 3): 2, (0, 0): 1}),\n",
       " FrozenMultiset({(1, 3): 1, (0, 3): 1, (0, 1): 1}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 1): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(3, 3): 1, (0, 1): 2}),\n",
       " FrozenMultiset({(1, 1): 1, (0, 3): 2})}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiset import FrozenMultiset\n",
    "contraction_list_list = generate_lorentz_contractions_from_dict(field_dict2)\n",
    "#print(contraction_list_list)\n",
    "contraction_set_set = set()\n",
    "for contraction_list in contraction_list_list:\n",
    "    #print('contraction_list:' +str(contraction_list))\n",
    "    contraction_set = FrozenMultiset(contraction_list)\n",
    "    print('contraction_set:' +str(contraction_set))\n",
    "    contraction_set_set.add(contraction_set)\n",
    "    \n",
    "contraction_set_set    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed redundant contraction set, but is there a way to avoid producing it in the first place?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_dict4 = {'D': 4, 'F': 2, 'Pb_S_P': 0, 'Pb_V_P': 3, 'Pb_T_P': 0, 'Pb_Vp_P': 0, 'Pb_Sp_P': 0}\n",
    "\n",
    "len(generate_lorentz_contractions_from_dict(field_dict4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraction_set:{(3, 3), (1, 1), (1, 1), (0, 0), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 1), (0, 0), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 1), (0, 0), (0, 0)}\n",
      "contraction_set:{(1, 1), (1, 3), (1, 3), (0, 0), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 3), (0, 0), (0, 0)}\n",
      "contraction_set:{(3, 3), (1, 1), (0, 1), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 1), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 3), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 3), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 3), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 1), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 1), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 1), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 1), (1, 1), (0, 3), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 3), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 3), (0, 3), (0, 0)}\n",
      "contraction_set:{(3, 3), (1, 1), (0, 1), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 1), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 3), (0, 0), (0, 1)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 3), (0, 0), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 3), (0, 0), (0, 1)}\n",
      "contraction_set:{(3, 3), (1, 1), (0, 0), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 0), (0, 1), (0, 1)}\n",
      "contraction_set:{(3, 3), (0, 1), (0, 1), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 3), (0, 1), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 1), (0, 1), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 3), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 3), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 0), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 0), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 0), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 1), (0, 1), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 3), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 3), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 1), (0, 1), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 3), (0, 1), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 3), (0, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 1), (0, 0), (0, 3)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 1), (0, 0), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 1), (0, 0), (0, 3)}\n",
      "contraction_set:{(1, 1), (1, 1), (0, 3), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 3), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 3), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 0), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 0), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 0), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 3), (0, 1), (0, 1), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 3), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (0, 3), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 1), (0, 1), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 3), (0, 1), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 3), (0, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 1), (1, 1), (0, 0), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 0), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 0), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 1), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 3), (0, 1), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 1), (0, 3), (0, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 1), (0, 1), (0, 3), (0, 3), (0, 3)}\n",
      "59\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "contraction_list_list4 = generate_lorentz_contractions_from_dict(field_dict4)\n",
    "contraction_set_set4 = set()\n",
    "for contraction_list in contraction_list_list4:\n",
    "    #print('contraction_list:' +str(contraction_list))\n",
    "    contraction_set = FrozenMultiset(contraction_list)\n",
    "    print('contraction_set:' +str(contraction_set))\n",
    "    contraction_set_set4.add(contraction_set)\n",
    "    \n",
    "#len(contraction_set_set4)\n",
    "print(len(contraction_list_list4))\n",
    "print(len(contraction_set_set4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, 1), (1, 1), (1, 1)]]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_dict3 = {'D': 0, 'F': 3, 'Pb_S_P': 0, 'Pb_V_P': 0, 'Pb_T_P': 0, 'Pb_Vp_P': 0, 'Pb_Sp_P': 0}\n",
    "\n",
    "generate_lorentz_contractions_from_dict(field_dict3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUG: can't distinguish between contractions on the same F and contractions on different F's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(3, 3), (1, 3), (1, 1), (0, 1), (0, 0)],\n",
       " [(3, 3), (1, 1), (1, 3), (0, 1), (0, 0)],\n",
       " [(1, 3), (1, 3), (1, 3), (0, 1), (0, 0)],\n",
       " [(3, 3), (1, 1), (1, 1), (0, 3), (0, 0)],\n",
       " [(1, 3), (1, 3), (1, 1), (0, 3), (0, 0)],\n",
       " [(1, 3), (1, 1), (1, 3), (0, 3), (0, 0)],\n",
       " [(1, 1), (1, 3), (1, 3), (0, 3), (0, 0)],\n",
       " [(3, 3), (1, 3), (1, 1), (0, 0), (0, 1)],\n",
       " [(3, 3), (1, 1), (1, 3), (0, 0), (0, 1)],\n",
       " [(1, 3), (1, 3), (1, 3), (0, 0), (0, 1)],\n",
       " [(3, 3), (1, 3), (0, 1), (0, 1), (0, 1)],\n",
       " [(3, 3), (1, 1), (0, 3), (0, 1), (0, 1)],\n",
       " [(1, 3), (1, 3), (0, 3), (0, 1), (0, 1)],\n",
       " [(3, 3), (1, 1), (0, 1), (0, 3), (0, 1)],\n",
       " [(1, 3), (1, 3), (0, 1), (0, 3), (0, 1)],\n",
       " [(1, 3), (1, 1), (0, 3), (0, 3), (0, 1)],\n",
       " [(1, 1), (1, 3), (0, 3), (0, 3), (0, 1)],\n",
       " [(3, 3), (1, 1), (1, 1), (0, 0), (0, 3)],\n",
       " [(1, 3), (1, 3), (1, 1), (0, 0), (0, 3)],\n",
       " [(1, 3), (1, 1), (1, 3), (0, 0), (0, 3)],\n",
       " [(1, 1), (1, 3), (1, 3), (0, 0), (0, 3)],\n",
       " [(3, 3), (1, 1), (0, 1), (0, 1), (0, 3)],\n",
       " [(1, 3), (1, 3), (0, 1), (0, 1), (0, 3)],\n",
       " [(1, 3), (1, 1), (0, 3), (0, 1), (0, 3)],\n",
       " [(1, 1), (1, 3), (0, 3), (0, 1), (0, 3)],\n",
       " [(1, 3), (1, 1), (0, 1), (0, 3), (0, 3)],\n",
       " [(1, 1), (1, 3), (0, 1), (0, 3), (0, 3)],\n",
       " [(1, 1), (1, 1), (0, 3), (0, 3), (0, 3)]]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_dict5 = {'D': 3, 'F': 2, 'Pb_S_P': 0, 'Pb_V_P': 3, 'Pb_T_P': 0, 'Pb_Vp_P': 0, 'Pb_Sp_P': 0}\n",
    "\n",
    "generate_lorentz_contractions_from_dict(field_dict5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraction_set:{(3, 3), (1, 3), (1, 1), (0, 1), (0, 0)}\n",
      "contraction_set:{(3, 3), (1, 1), (1, 3), (0, 1), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 3), (0, 1), (0, 0)}\n",
      "contraction_set:{(3, 3), (1, 1), (1, 1), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 1), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 1), (0, 3), (0, 0)}\n",
      "contraction_set:{(1, 1), (1, 3), (1, 3), (0, 3), (0, 0)}\n",
      "contraction_set:{(3, 3), (1, 3), (1, 1), (0, 0), (0, 1)}\n",
      "contraction_set:{(3, 3), (1, 1), (1, 3), (0, 0), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 3), (0, 0), (0, 1)}\n",
      "contraction_set:{(3, 3), (1, 3), (0, 1), (0, 1), (0, 1)}\n",
      "contraction_set:{(3, 3), (1, 1), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 3), (0, 1), (0, 1)}\n",
      "contraction_set:{(3, 3), (1, 1), (0, 1), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 1), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(3, 3), (1, 1), (1, 1), (0, 0), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 1), (0, 0), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 3), (1, 1), (0, 0), (0, 3)}\n",
      "contraction_set:{(1, 1), (1, 3), (1, 3), (0, 0), (0, 3)}\n",
      "contraction_set:{(3, 3), (1, 1), (0, 1), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 3), (0, 1), (0, 1), (0, 3)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 3), (0, 3), (0, 1)}\n",
      "contraction_set:{(1, 3), (1, 1), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 1), (1, 3), (0, 1), (0, 3), (0, 3)}\n",
      "contraction_set:{(1, 1), (1, 1), (0, 3), (0, 3), (0, 3)}\n",
      "28\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{FrozenMultiset({(1, 1): 2, (0, 3): 3}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 1): 2, (0, 3): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(1, 3): 2, (1, 1): 1, (0, 3): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 3): 1, (1, 1): 1, (0, 1): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(1, 3): 2, (0, 3): 1, (0, 1): 2}),\n",
       " FrozenMultiset({(1, 3): 3, (0, 1): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 1): 1, (0, 3): 1, (0, 1): 2}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 3): 1, (0, 1): 3}),\n",
       " FrozenMultiset({(1, 3): 1, (1, 1): 1, (0, 3): 2, (0, 1): 1})}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contraction_list_list5 = generate_lorentz_contractions_from_dict(field_dict5)\n",
    "contraction_set_set5 = set()\n",
    "for contraction_list in contraction_list_list5:\n",
    "    #print('contraction_list:' +str(contraction_list))\n",
    "    contraction_set = FrozenMultiset(contraction_list)\n",
    "    print('contraction_set:' +str(contraction_set))\n",
    "    contraction_set_set5.add(contraction_set)\n",
    "    \n",
    "#len(contraction_set_set4)\n",
    "print(len(contraction_list_list5))\n",
    "print(len(contraction_set_set5))\n",
    "contraction_set_set5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{FrozenMultiset({(1, 1): 2, (0, 3): 3}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 1): 2, (0, 3): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(1, 3): 2, (1, 1): 1, (0, 3): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 3): 1, (1, 1): 1, (0, 1): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(1, 3): 2, (0, 3): 1, (0, 1): 2}),\n",
       " FrozenMultiset({(1, 3): 3, (0, 1): 1, (0, 0): 1}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 1): 1, (0, 3): 1, (0, 1): 2}),\n",
       " FrozenMultiset({(3, 3): 1, (1, 3): 1, (0, 1): 3}),\n",
       " FrozenMultiset({(1, 3): 1, (1, 1): 1, (0, 3): 2, (0, 1): 1})}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test reduce_set_of_contraction_sets()\n",
    "reduced_set_of_contraction_sets(field_dict5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate all Field Combinations up to a Given Mass Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbols_to_fields(field_combo_symbols):\n",
    "    field_combo = []\n",
    "    for field_symbol in field_combo_symbols:\n",
    "        if field_symbol == 'D':\n",
    "            field_combo.append(D)\n",
    "            continue\n",
    "        if field_symbol == 'F':\n",
    "            field_combo.append(F)\n",
    "            continue\n",
    "        if field_symbol == 'Pb_S_P':\n",
    "            field_combo.append(S)\n",
    "            continue\n",
    "        if field_symbol == 'Pb_V_P':\n",
    "            field_combo.append(V)\n",
    "            continue\n",
    "        if field_symbol == 'Pb_T_P':\n",
    "            field_combo.append(T)\n",
    "            continue\n",
    "        if field_symbol == 'Pb_Vp_P':\n",
    "            field_combo.append(Vp)\n",
    "            continue\n",
    "        if field_symbol == 'Pb_Sp_P':\n",
    "            field_combo.append(Sp)\n",
    "            continue\n",
    "         \n",
    "    return field_combo\n",
    "\n",
    "def totalMassDim(field_combo_symbols):\n",
    "    field_combo = symbols_to_fields(field_combo_symbols)\n",
    "    m = 0\n",
    "    for field in field_combo:\n",
    "        m += field.get_massDim()\n",
    "    return m\n",
    "\n",
    "def generate_field_combos(massDim):\n",
    "    # EXPLANATION: Generate all multisets of the symbols [D, F, S, V, T, Vp, Sp] up to massDim. store in a set of \n",
    "    # multisets called set_of_field_multisets. generate new multisets by adding each field to multisets in a set\n",
    "    # of multisets called front. remove a multiset from front after attempting to add each field to it. add an\n",
    "    # element to front only if after a field has been added, its mass dimension is still less than massDim. returns\n",
    "    # set_of_multisets, a dictionary mapping each mass dimension up to massDim to a set of multisets. \n",
    "    \n",
    "    # declare field types\n",
    "    D = field('D', 1, 1, 0, 0)\n",
    "    F = field('F', 2, 2, 0, 0)\n",
    "    S = field('Pb_S_P', 3, 0, 0, 0)\n",
    "    V = field('Pb_V_P', 3, 0, 0, 0)\n",
    "    T = field('Pb_T_P', 3, 0, 0, 0)\n",
    "    Vp = field('Pb_Vp_P', 3, 0, 0, 0)\n",
    "    Sp = field('Pb_Sp_P', 3, 0, 0, 0)\n",
    "    \n",
    "    # make list of field types\n",
    "    fields = [D, F, S, V, T, Vp, Sp] \n",
    "    \n",
    "    # set of multisets\n",
    "    set_of_field_multisets = {}\n",
    "    for m in range(massDim + 1): #set of multisets of field strings, arranged by massDim\n",
    "        set_of_field_multisets[m] = set()\n",
    "    front = set() #set of multisets of field strings, set of multisets to add to to make new multisets\n",
    "    \n",
    "    # initialize front\n",
    "    for item in fields: \n",
    "        m = item.get_massDim()\n",
    "        if m <= massDim:\n",
    "            front.add(FrozenMultiset([item.get_symbol()]))\n",
    "            set_of_field_multisets[m].add(FrozenMultiset([item.get_symbol()]))\n",
    "\n",
    "    # build set_of_multisets\n",
    "    while front:\n",
    "        #print('')\n",
    "        #print('front: ' + str(front))\n",
    "        front_new = front.copy()\n",
    "        for field_multiset in front:\n",
    "            #print('field_multiset: ' + str(field_multiset))\n",
    "            for item in fields:\n",
    "                #print('field item: ' + str(item.get_symbol()))\n",
    "                field_multiset_new = field_multiset.combine(FrozenMultiset([item.get_symbol()]))\n",
    "                #print('field_multiset_new: ' + str(field_multiset_new))\n",
    "                m = totalMassDim(field_multiset_new)\n",
    "                if m < massDim:\n",
    "                    set_of_field_multisets[m].add(field_multiset_new)\n",
    "                    front_new.add(field_multiset_new)\n",
    "                    #print('ADD TO FRONT: ' + str(field_multiset_new))\n",
    "                if m == massDim:\n",
    "                    set_of_field_multisets[m].add(field_multiset_new)\n",
    "            front_new.remove(field_multiset)\n",
    "        front = front_new\n",
    "        #print('front_new: ' + str(front_new))\n",
    "        #print('')\n",
    "    \n",
    "    return set_of_field_multisets\n",
    "                    \n",
    "                    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: set()\n",
      "\n",
      "1: {FrozenMultiset({'D': 1})}\n",
      "\n",
      "2: {FrozenMultiset({'F': 1}), FrozenMultiset({'D': 2})}\n",
      "\n",
      "3: {FrozenMultiset({'Pb_Vp_P': 1}), FrozenMultiset({'Pb_T_P': 1}), FrozenMultiset({'D': 1, 'F': 1}), FrozenMultiset({'D': 3}), FrozenMultiset({'Pb_Sp_P': 1}), FrozenMultiset({'Pb_S_P': 1}), FrozenMultiset({'Pb_V_P': 1})}\n",
      "\n",
      "4: {FrozenMultiset({'Pb_T_P': 1, 'D': 1}), FrozenMultiset({'D': 1, 'Pb_Sp_P': 1}), FrozenMultiset({'Pb_Vp_P': 1, 'D': 1}), FrozenMultiset({'F': 2}), FrozenMultiset({'D': 2, 'F': 1}), FrozenMultiset({'D': 1, 'Pb_S_P': 1}), FrozenMultiset({'D': 1, 'Pb_V_P': 1}), FrozenMultiset({'D': 4})}\n",
      "\n",
      "5: {FrozenMultiset({'D': 2, 'Pb_S_P': 1}), FrozenMultiset({'D': 1, 'F': 2}), FrozenMultiset({'F': 1, 'Pb_Sp_P': 1}), FrozenMultiset({'Pb_Vp_P': 1, 'D': 2}), FrozenMultiset({'F': 1, 'Pb_S_P': 1}), FrozenMultiset({'F': 1, 'Pb_V_P': 1}), FrozenMultiset({'Pb_Vp_P': 1, 'F': 1}), FrozenMultiset({'D': 2, 'Pb_Sp_P': 1}), FrozenMultiset({'D': 5}), FrozenMultiset({'Pb_T_P': 1, 'D': 2}), FrozenMultiset({'D': 3, 'F': 1}), FrozenMultiset({'Pb_T_P': 1, 'F': 1}), FrozenMultiset({'D': 2, 'Pb_V_P': 1})}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "massDim = 5\n",
    "for key in generate_field_combos(massDim):\n",
    "    print(str(key) + ': ' + str(generate_field_combos(massDim)[key]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tested for massdim up to 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate All Lorentz Contractions for Every Field Combination up to a Given Mass Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lorentz_contractions_from_massDim(massDim, up_to = True):\n",
    "    # ARGUMENTS\n",
    "    # massDim: mass dimension \n",
    "    # up_to = whether to produce lorentz contracted field combos up to and including massDim (up_to = True) or only\n",
    "    # at massDim (up_to = False)\n",
    "    #\n",
    "    # EXPLANATION: generates all lorentz contractions of all field combinations at, or up to and including, massDim.\n",
    "    # if up_to = True, the function outputs a dictionary with keys m corresponding to every mass dimension up to and\n",
    "    # including massDim; the values are themselves dictionaries, with keys equal to different field combinations\n",
    "    # of mass dimension m, and values equal to sets of multisets of lorentz contractions of fields in the combo. \n",
    "    # each multiset corresponds to a distinct way of contracting the fields in a given field combination. if \n",
    "    # up_to = False, then simply return the dictionary corresponding to mass dimension massDim, whose keys are\n",
    "    # field combinations of mass dimension massDim and whose values are sets of multisets of lorentz contractions. \n",
    "    \n",
    "    if up_to == True:\n",
    "        lorentz_contracted_combos = {}\n",
    "        set_of_field_multisets = generate_field_combos(massDim)\n",
    "        for m in set_of_field_multisets.keys():\n",
    "            lorentz_contracted_combos_m = {}\n",
    "            for combo in set_of_field_multisets[m]:\n",
    "                field_combo = dict(combo.items())\n",
    "                lorentz_contracted_combos_m[combo] = reduced_set_of_contraction_sets(field_combo)\n",
    "            lorentz_contracted_combos[m] = lorentz_contracted_combos_m\n",
    "        return lorentz_contracted_combos\n",
    "    else: \n",
    "        lorentz_contracted_combos_m = {}\n",
    "        set_of_field_multisets = generate_field_combos(massDim)\n",
    "        for combo in set_of_field_multisets[massDim]:\n",
    "            field_combo = dict(combo.items())\n",
    "            lorentz_contracted_combos_m[combo] = reduced_set_of_contraction_sets(field_combo)\n",
    "        return lorentz_contracted_combos_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{F, Pb_S_P, D}\n",
      "{FrozenMultiset({(0, 0): 1}), FrozenMultiset({(0, 2): 1})}\n",
      "{Pb_Sp_P, Pb_Sp_P}\n",
      "{FrozenMultiset({})}\n",
      "{Pb_T_P, Pb_V_P}\n",
      "{FrozenMultiset({(0, 1): 1}), FrozenMultiset({(0, 0): 1})}\n",
      "{F, F, F}\n",
      "{FrozenMultiset({(0, 0): 3})}\n",
      "{Pb_Vp_P, Pb_Vp_P}\n",
      "{FrozenMultiset({(0, 0): 1})}\n",
      "{Pb_S_P, Pb_V_P}\n",
      "{FrozenMultiset({})}\n",
      "{D, Pb_Sp_P, F}\n",
      "{FrozenMultiset({(0, 2): 1})}\n",
      "{Pb_Vp_P, Pb_S_P}\n",
      "{FrozenMultiset({})}\n",
      "{Pb_V_P, Pb_V_P}\n",
      "{FrozenMultiset({(0, 0): 1})}\n",
      "{D, D, D, D, D, D}\n",
      "{FrozenMultiset({(0, 0): 3})}\n",
      "{D, D, D, Pb_Vp_P}\n",
      "{FrozenMultiset({(0, 1): 1, (0, 0): 1})}\n",
      "{Pb_S_P, Pb_S_P}\n",
      "{FrozenMultiset({})}\n",
      "{Pb_Sp_P, Pb_S_P}\n",
      "{FrozenMultiset({})}\n",
      "{Pb_Vp_P, Pb_Sp_P}\n",
      "{FrozenMultiset({})}\n",
      "{Pb_T_P, F, D}\n",
      "{FrozenMultiset({(1, 2): 1, (0, 0): 1}), FrozenMultiset({(0, 1): 2}), FrozenMultiset({(1, 1): 1, (0, 0): 1}), FrozenMultiset({(0, 2): 1, (0, 1): 1})}\n",
      "{Pb_Vp_P, Pb_V_P}\n",
      "{FrozenMultiset({(0, 1): 1})}\n",
      "{Pb_Vp_P, D, F}\n",
      "{FrozenMultiset({(1, 2): 1, (0, 2): 1}), FrozenMultiset({(2, 2): 1, (0, 1): 1})}\n",
      "{Pb_Sp_P, Pb_V_P}\n",
      "{FrozenMultiset({})}\n",
      "{D, D, D, Pb_S_P}\n",
      "{FrozenMultiset({(0, 0): 1})}\n",
      "{Pb_T_P, Pb_T_P}\n",
      "{FrozenMultiset({(0, 0): 2})}\n",
      "{Pb_T_P, Pb_S_P}\n",
      "{FrozenMultiset({(0, 0): 1})}\n",
      "{D, F, Pb_V_P}\n",
      "{FrozenMultiset({(1, 2): 1, (0, 1): 1}), FrozenMultiset({(1, 1): 1, (0, 2): 1})}\n",
      "{D, D, D, Pb_V_P}\n",
      "{FrozenMultiset({(0, 1): 1, (0, 0): 1})}\n",
      "{D, D, F, F}\n",
      "{FrozenMultiset({(1, 1): 1, (0, 1): 2}), FrozenMultiset({(1, 1): 2, (0, 0): 1})}\n",
      "{D, D, D, Pb_Sp_P}\n",
      "{FrozenMultiset({(0, 0): 1})}\n",
      "{Pb_T_P, Pb_Sp_P}\n",
      "{FrozenMultiset({(0, 0): 1})}\n",
      "{D, D, D, D, F}\n",
      "{FrozenMultiset({(1, 1): 1, (0, 0): 2}), FrozenMultiset({(0, 1): 2, (0, 0): 1})}\n",
      "{D, D, D, Pb_T_P}\n",
      "{FrozenMultiset({(0, 1): 1, (0, 0): 1}), FrozenMultiset({(0, 1): 2})}\n",
      "{Pb_Vp_P, Pb_T_P}\n",
      "{FrozenMultiset({(0, 1): 1})}\n"
     ]
    }
   ],
   "source": [
    "massDim = 6\n",
    "lorentz_contraction_dict = generate_lorentz_contractions_from_massDim(massDim, up_to = False)\n",
    "for field_combo in lorentz_contraction_dict.keys():\n",
    "    print(field_combo)\n",
    "    print(lorentz_contraction_dict[field_combo])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
